{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8399b438",
   "metadata": {},
   "source": [
    "PURPOSE OF THIS NOTEBOOK:  \n",
    "In this notebook, we turn raw,human readable information into numerical representations that a model can learn from without leaking the target.  \n",
    "_leaking the target: model gets hints about the answer accidently while training_  \n",
    "- This happens when something in the input given for training contains information that would not be available at predictio time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce924e63",
   "metadata": {},
   "source": [
    "_TEXT COLUMNS :_  \n",
    "- For the model, different text sections don't matter. They are just words. So we concatenate text by presenting it with everything the employer offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa222b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/processed/cleaned_job_postings.csv\")\n",
    "df.shape\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_remote\"] = df[\"location\"].str.lower().str.contains(\"remote\").astype(int)\n",
    "df=df.drop(columns=[\"salary_range\",\"department\",\"location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = [\n",
    "    \"title\", \n",
    "    \"company_profile\", \n",
    "    \"description\",\n",
    "    \"requirements\",\n",
    "    \"benefits\"\n",
    "    ]\n",
    "binary_columns = [\n",
    "    \"telecommuting\",\n",
    "    \"has_company_logo\",\n",
    "    \"has_questions\",\n",
    "]\n",
    "\n",
    "categorical_columns = [\n",
    "    \"is_remote\", \n",
    "    \"employment_type\",\n",
    "    \"required_experience\",\n",
    "    \"required_education\",\n",
    "    \"industry\",\n",
    "    \"function\",\n",
    "]\n",
    "\n",
    "target_column=\"fraudulent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec798ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force text columns into string\n",
    "for col in text_columns:\n",
    "    df[col]=df[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e972ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"full_text\"]=df[text_columns].agg(\" \".join,axis=1)\n",
    "# Joins text row wise, inserting spaces between sections\n",
    "df=df.drop(columns=text_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c93269",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(columns=[target_column])\n",
    "y=df[target_column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11db9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraudulent\n",
       "0    0.951622\n",
       "1    0.048378\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# While splitting, preserve the original class distribution\n",
    "# Test size= 0.2 implies 20% of the data will be used for testing, and 80% for training\n",
    "# X is the feature set, and y is the target variable\n",
    "\"\"\"\n",
    "X_train : Features used to train the model\n",
    "Y_train : Correct answers for the training data\n",
    "X_test : Features used to evaluate the model's performance\n",
    "Y_test : Correct answers for the testing data\"\"\"\n",
    "y_train.value_counts(normalize=True)\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98760f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#To convert text data into numerical features using TF-IDF vectorization\n",
    "tfidf=TfidfVectorizer(max_features=5000, stop_words=\"english\",min_df=5)\n",
    "\n",
    "#stop_words remove common words that do not carry much meaning (e.g., \"the\", \"is\", \"and\")\n",
    "#min_df=5 means that only words that appear in at least 5 documents will be included\n",
    "#max_features=5000 limits the number of features to the top 5000 most important words based on their TF-IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f696c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14304, 5000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text = tfidf.fit_transform(X_train[\"full_text\"])\n",
    "X_test_text=tfidf.transform(X_test[\"full_text\"])\n",
    "\"\"\"\n",
    "fit_tranform learns the vocabulary from the training data and transforms it into a matrix of TF-IDF features.\n",
    "transform applies the same transformation to the test data using the vocabulary learned from the training data.\n",
    "\"\"\"\n",
    "X_train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f77b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14304, 5000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a3909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_structured=X_train.drop(columns=[\"full_text\"])\n",
    "X_test_structured=X_test.drop(columns=[\"full_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b870eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_remote : <bound method IndexOpsMixin.nunique of 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "17875    0\n",
      "17876    0\n",
      "17877    0\n",
      "17878    0\n",
      "17879    0\n",
      "Name: is_remote, Length: 17880, dtype: int64>\n",
      "employment_type : <bound method IndexOpsMixin.nunique of 0            Other\n",
      "1        Full-time\n",
      "2          Unknown\n",
      "3        Full-time\n",
      "4        Full-time\n",
      "           ...    \n",
      "17875    Full-time\n",
      "17876    Full-time\n",
      "17877    Full-time\n",
      "17878     Contract\n",
      "17879    Full-time\n",
      "Name: employment_type, Length: 17880, dtype: object>\n",
      "required_experience : <bound method IndexOpsMixin.nunique of 0              Internship\n",
      "1          Not Applicable\n",
      "2                 Unknown\n",
      "3        Mid-Senior level\n",
      "4        Mid-Senior level\n",
      "               ...       \n",
      "17875    Mid-Senior level\n",
      "17876    Mid-Senior level\n",
      "17877             Unknown\n",
      "17878      Not Applicable\n",
      "17879    Mid-Senior level\n",
      "Name: required_experience, Length: 17880, dtype: object>\n",
      "required_education : <bound method IndexOpsMixin.nunique of 0                  Unknown\n",
      "1                  Unknown\n",
      "2                  Unknown\n",
      "3        Bachelor's Degree\n",
      "4        Bachelor's Degree\n",
      "               ...        \n",
      "17875              Unknown\n",
      "17876    Bachelor's Degree\n",
      "17877              Unknown\n",
      "17878         Professional\n",
      "17879              Unknown\n",
      "Name: required_education, Length: 17880, dtype: object>\n",
      "industry : <bound method IndexOpsMixin.nunique of 0                          Unknown\n",
      "1        Marketing and Advertising\n",
      "2                          Unknown\n",
      "3                Computer Software\n",
      "4           Hospital & Health Care\n",
      "                   ...            \n",
      "17875            Computer Software\n",
      "17876                     Internet\n",
      "17877                      Unknown\n",
      "17878               Graphic Design\n",
      "17879            Computer Software\n",
      "Name: industry, Length: 17880, dtype: object>\n",
      "function : <bound method IndexOpsMixin.nunique of 0                   Marketing\n",
      "1            Customer Service\n",
      "2                     Unknown\n",
      "3                       Sales\n",
      "4        Health Care Provider\n",
      "                 ...         \n",
      "17875                   Sales\n",
      "17876     Accounting/Auditing\n",
      "17877                 Unknown\n",
      "17878                  Design\n",
      "17879             Engineering\n",
      "Name: function, Length: 17880, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "for col in categorical_columns:\n",
    "    print(col,\":\",df[col].nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc606f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder=OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "#\"ignore\" means that if the encoder encounters a category in the test data that it did not see during training, it will ignore it instead of raising an error.\n",
    "# sparse_output=False means that the output will be a dense array instead of a sparse matrix, which can be easier to work with for small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eca5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_categorical = encoder.fit_transform(X_train_structured[categorical_columns])\n",
    "#Learns all category levels and converts the categorical features in the training set into a one-hot encoded format.\n",
    "X_test_categorical= encoder.transform(X_test_structured[categorical_columns])\n",
    "# Transorm test categorical data\n",
    "X_train_binary=X_train_structured[binary_columns].values\n",
    "X_test_binary=X_test_structured[binary_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed82727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "X_train_final=hstack([X_train_text,X_train_categorical,X_train_binary])\n",
    "X_test_final=hstack([X_test_text,X_test_categorical,X_test_binary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255cb12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/onehot_encoder.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Save TF-IDF vectorizer\n",
    "joblib.dump(tfidf, \"../models/tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Save encoder\n",
    "joblib.dump(encoder, \"../models/onehot_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26409c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3576, 5201)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d9dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import save_npz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a689262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sparse feature matrices\n",
    "save_npz(\"../data/processed/X_train_final.npz\", X_train_final)\n",
    "save_npz(\"../data/processed/X_test_final.npz\", X_test_final)\n",
    "\n",
    "# Save target arrays\n",
    "np.save(\"../data/processed/y_train.npy\", y_train.values)\n",
    "np.save(\"../data/processed/y_test.npy\", y_test.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
