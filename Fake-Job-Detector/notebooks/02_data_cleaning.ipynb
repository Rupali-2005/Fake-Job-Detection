{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88131f5a",
   "metadata": {},
   "source": [
    "PURPOSE OF THIS NOTEBOOK:  \n",
    "This notebook focuses on preparing a clean, consistent and model ready data set by handling missing values, noisy text fields and irrelevant features while preserving information critical for fraud detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46dc73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17880, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv(\"../data/raw/fake_job_postings.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3496fcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salary_range           83.959732\n",
       "department             64.580537\n",
       "required_education     45.329978\n",
       "benefits               40.335570\n",
       "required_experience    39.429530\n",
       "function               36.101790\n",
       "industry               27.421700\n",
       "employment_type        19.412752\n",
       "company_profile        18.501119\n",
       "requirements           15.078300\n",
       "location                1.935123\n",
       "description             0.005593\n",
       "title                   0.000000\n",
       "job_id                  0.000000\n",
       "telecommuting           0.000000\n",
       "has_questions           0.000000\n",
       "has_company_logo        0.000000\n",
       "fraudulent              0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the percentage of missing values for each column\n",
    "missing_percent = df.isnull().mean().sort_values(ascending=False) * 100\n",
    "missing_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0067538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Often in fraud detection, inconsistencies or missing data can be indicators of fraudulent activity rather than noise\n",
    "\n",
    "text_columns = [ # Usually it is noticed that fraud jobs have thin or missing text\n",
    "    \"title\", #often use vague titles and overuse buzzwords\n",
    "    \"company_profile\", #fake job posts often have incomplete or generic company profiles\n",
    "    \"description\",\n",
    "    \"requirements\",\n",
    "    \"benefits\", #fake job posts often list no benefits or exaggerate them\n",
    "]\n",
    "\n",
    "binary_columns = [\n",
    "    \"telecommuting\",\n",
    "    \"has_company_logo\",\n",
    "    \"has_questions\",\n",
    "]\n",
    "# these are the columns where missing values are signals not noise\n",
    "categorical_columns = [\n",
    "    \"location\", #usually vague or unrealistic in fraudlent jobs. \n",
    "    \"department\", \n",
    "    \"salary_range\",\n",
    "    \"employment_type\",\n",
    "    \"required_experience\",\n",
    "    \"required_education\",\n",
    "    \"industry\",\n",
    "    \"function\",\n",
    "]\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"job_id\" #unique identifier, not useful for prediction\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d281a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To hangle missing string values, we replace them with an empty string\n",
    "df[text_columns] = df[text_columns].fillna(\"\")\n",
    "\n",
    "# For binary columns, we replace missing values with 0, assuming that missing indicates absence\n",
    "df[binary_columns] = df[binary_columns].fillna(0)\n",
    "\n",
    "# For categorical columns, we replace missing values with 'Unknown'\n",
    "df[categorical_columns] = df[categorical_columns].fillna(\"Unknown\")\n",
    "\n",
    "df.drop(columns=[\"job_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a888f",
   "metadata": {},
   "source": [
    "- For text features, we use empty string when absence itself is information like title, profile, etc. Missing values represent absence of linguistic content which in itself can signal fraudlent.  \n",
    "- On the other hand, for categorical features, missing values indicate an unspecified state and hence we use \"Unknown\" to preserve interpretability.  \n",
    "\n",
    "***How does this mathematically matter?***  \n",
    "Empty string maps to a zero vector whose distributional correlation with fraud can make it highly informative.  \n",
    "On the other hand, unknown is a token in its own right and competes with others, owned by both real and fraudlent jobs.  \n",
    "Text featues being absent represents lack of explanation and is abnormal, often indicative of low effort which correlates strongly with fraud.  \n",
    "Categorical fields being missing is _often_ legitimate even for real jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20806ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text=text.lower()\n",
    "    text=text.strip()\n",
    "    return text\n",
    "\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].apply(clean_text)\n",
    "\n",
    "df[\"combined_text\"] = (df[\"title\"] + \" \" + df[\"company_profile\"] + \" \" + df[\"description\"] + \" \" + df[\"requirements\"] + \" \" + df[\"benefits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a7df15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                  0\n",
       "location               0\n",
       "department             0\n",
       "salary_range           0\n",
       "company_profile        0\n",
       "description            0\n",
       "requirements           0\n",
       "benefits               0\n",
       "telecommuting          0\n",
       "has_company_logo       0\n",
       "has_questions          0\n",
       "employment_type        0\n",
       "required_experience    0\n",
       "required_education     0\n",
       "industry               0\n",
       "function               0\n",
       "fraudulent             0\n",
       "combined_text          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check if there are any remaining missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d63a9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraudulent\n",
       "0    95.1566\n",
       "1     4.8434\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"fraudulent\"].value_counts(normalize=True)*100\n",
    "#To find the percentage of fraudulent vs non-fraudulent job posts in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec7439dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/processed/cleaned_job_postings.csv\", index=False)\n",
    "# We put index = False to avoid adding an extra index column in the output csv file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
